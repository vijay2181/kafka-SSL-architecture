3 NODE ZOOKEEPER AND KAFKA WITH SSSL:-
======================================

take 3 t2.medium instances which are amazon-linux flavoured

SERVER1: ZOOKEEPER1, KAFKA1, CLIENT1
SERVER1: ZOOKEEPER2, KAFKA2, CLIENT2
SERVER1: ZOOKEEPER3, KAFKA3, CLIENT3

allow 22,80,2181,2888-3888,9093 ports


- in 3.0.0 or above kafka version, zookeeper comes by default
Apache Kafka depends on Zookeeper for cluster management. Hence, prior to starting Kafka, Zookeeper has to be started. There is no need to explicitly install Zookeeper, as it comes included with Apache Kafka.
- during coming days in 4.0.0 versions, there is no need of zookeeper

- download kafka from official page


IP ADDRESSES:
=============
SERVER1 35.90.113.2543   ec2-35-90-113-2543.us-west-2.compute.amazonaws.com
SERVER2 52.43.209.2403   ec2-52-43-209-2403.us-west-2.compute.amazonaws.com
SERVER3 54.187.78.1003   ec2-54-187-78-1003.us-west-2.compute.amazonaws.com


IN SERVER1:-
============

STEPS:-
-------

1.CREATE A CA(you will get publec cert and private key)
2.create a server(kafka brokers) certificates

cd /home/ec2-user
mkdir ssl
cd ssl

run the certs.sh scripts by mentioning 3 servers public dns names in it, this script will create certs for SERVER1,SERVER2,SERVER3,client CERTS

vi certs.sh
SERVER1=ec2-35-90-113-2543.us-west-2.compute.amazonaws.com
SERVER2=ec2-52-43-209-2403.us-west-2.compute.amazonaws.com
SERVER3=ec2-54-187-78-1003.us-west-2.compute.amazonaws.com

bash certs.sh

inside ssl folder you will get ca and secrets folder, all the certs and passowrd will be in secrets folder

keytool -v --list --keystore ec2-35-90-113-2543.us-west-2.compute.amazonaws.com.keystore.jks


- so in SERVER1 we have created all certs, now we need to copy truststores and keystores and send to respective servers SERVER2, SERVER3, client if we have any client
 - copy the server private key and paste in secrects folder


cd /home/ec2-user/secrets
vi server.pem                            ---- copy pem file which is used for 3 servers
chmod 400 server.pem

SENDING FOR SERVER1/Local:
--------------------------
cp -r ec2-35-90-113-2543.us-west-2.compute.amazonaws.com.keystore.jks ec2-35-90-113-2543.us-west-2.compute.amazonaws.com.truststore.jks cert_creds /home/ec2-user/ 

SENDING FOR SERVER2:
--------------------
scp -i /home/ec2-user/ssl/secrets/server.pem ec2-52-43-209-2403.us-west-2.compute.amazonaws.com.keystore.jks ec2-52-43-209-2403.us-west-2.compute.amazonaws.com.truststore.jks cert_creds ec2-user@ec2-52-43-209-2403.us-west-2.compute.amazonaws.com:/home/ec2-user/ 

SENDING FOR SERVER3:
--------------------
scp -i /home/ec2-user/ssl/secrets/server.pem ec2-54-187-78-1003.us-west-2.compute.amazonaws.com.keystore.jks ec2-54-187-78-1003.us-west-2.compute.amazonaws.com.truststore.jks cert_creds ec2-user@ec2-54-187-78-1003.us-west-2.compute.amazonaws.com:/home/ec2-user/ 


- now you can check in SERVER2,SERVER3 that there are truststore,keystore,password files 


INSTALL ZOOKEEPER:
==================

Apache Kafka depends on Zookeeper for cluster management. Hence, prior to starting Kafka, Zookeeper has to be started. There is no need to explicitly install Zookeeper, as it comes included with Apache Kafka.
- during coming days in 4.0.0 versions, there is no need of zookeeper


cd /home/ec2-user
sudo yum install java-11-amazon-corretto-headless -y
wget https://downloads.apache.org/kafka/3.5.1/kafka_2.13-3.5.1.tgz
tar -xvf kafka_2.13-3.5.1.tgz
mkdir zookeeper
mkdir kafka-logs
cp -r  kafka_2.13-3.5.1/config/zookeeper.properties kafka_2.13-3.5.1/config/zookeeper.properties-bkp

vi /home/ec2-user/zookeeper/myid
1

vi kafka_2.13-3.5.1/config/zookeeper.properties
tickTime=2000
initLimit=10
syncLimit=5
clientPort=2181
dataDir=/home/ec2-user/zookeeper
maxClientCnxns=60
autopurge.snapRetainCount=3
autopurge.purgeInterval=1
4lw.commands.whitelist=*
server.1=0.0.0.0:2888:3888
server.2=52.43.209.2403:2888:3888
server.3=54.187.78.1003:2888:3888


IN SERVER2:-
=============
cd /home/ec2-user
sudo yum install java-11-amazon-corretto-headless -y
wget https://downloads.apache.org/kafka/3.5.1/kafka_2.13-3.5.1.tgz
tar -xvf kafka_2.13-3.5.1.tgz
mkdir zookeeper
cp -r  kafka_2.13-3.5.1/config/zookeeper.properties kafka_2.13-3.5.1/config/zookeeper.properties-bkp

vi /home/ec2-user/zookeeper/myid
2

vi kafka_2.13-3.5.1/config/zookeeper.properties
tickTime=2000
initLimit=10
syncLimit=5
clientPort=2181
dataDir=/home/ec2-user/zookeeper
maxClientCnxns=60
autopurge.snapRetainCount=3
autopurge.purgeInterval=1
4lw.commands.whitelist=*
server.1=35.90.113.2543:2888:3888
server.2=0.0.0.0:2888:3888
server.3=54.187.78.1003:2888:3888



IN SERVER3:
===========
cd /home/ec2-user
sudo yum install java-11-amazon-corretto-headless -y
wget https://downloads.apache.org/kafka/3.5.1/kafka_2.13-3.5.1.tgz
tar -xvf kafka_2.13-3.5.1.tgz
mkdir zookeeper
cp -r  kafka_2.13-3.5.1/config/zookeeper.properties kafka_2.13-3.5.1/config/zookeeper.properties-bkp

vi /home/ec2-user/zookeeper/myid
3

vi kafka_2.13-3.5.1/config/zookeeper.properties
tickTime=2000
initLimit=10
syncLimit=5
clientPort=2181
dataDir=/home/ec2-user/zookeeper
maxClientCnxns=60
autopurge.snapRetainCount=3
autopurge.purgeInterval=1
4lw.commands.whitelist=*
server.1=35.90.113.2543:2888:3888
server.2=52.43.209.2403:2888:3888
server.3=0.0.0.0:2888:3888



START ZOOKEEPER
===============
start zookeeper in all SERVER1,SERVER2,SERVER3 instances at once

cd kafka_2.13-3.5.1/bin
/home/ec2-user/kafka_2.13-3.5.1/bin/zookeeper-server-start.sh /home/ec2-user/kafka_2.13-3.5.1/config/zookeeper.properties 
the above command starts zookeeper in foreground, if you want to start in background, then use -daemon

/home/ec2-user/kafka_2.13-3.5.1/bin/zookeeper-server-start.sh -daemon /home/ec2-user/kafka_2.13-3.5.1/config/zookeeper.properties 

/home/ec2-user/kafka_2.13-3.5.1/bin/zookeeper-server-stop.sh -daemon /home/ec2-user/kafka_2.13-3.5.1/config/zookeeper.properties


ZOOKEEPER LOGS:
===============
zookeeper logs will be found in 
/home/ec2-user/kafka_2.13-3.5.1/logs
tail -f /home/ec2-user/kafka_2.13-3.5.1/logs/zookeeper.out
tail -f -n 100 /home/ec2-user/kafka_2.13-3.5.1/logs/zookeeper.out
ps -ef | grep zookeeper
netstat -tulpn | grep LISTEN
sudo yum install nc -y
echo stat | nc localhost 2181
- above command 'stat' which is 4 letter(4lw.commands.whitelist=*) is removed from whitelist, but by default they are whitelisted for security reasons.



KAFKA CONFIGURATION:
====================

KAFKA1:
-------
cp -r /home/ec2-user/kafka_2.13-3.5.1/config/server.properties /home/ec2-user/kafka_2.13-3.5.1/config/server.properties-bkp
vi /home/ec2-user/kafka_2.13-3.5.1/config/server.properties
broker.id=1
listeners=SSL://0.0.0.0:9093
#advertised.listeners=SSL://<SERVER1_PUBLIC_DNS>:9093
advertised.listeners=SSL://ec2-35-90-113-2543.us-west-2.compute.amazonaws.com:9093
ssl.keystore.location=/home/ec2-user/ec2-52-43-209-2403.us-west-2.compute.amazonaws.com.keystore.jks
ssl.keystore.password=password
ssl.key.password=password
ssl.truststore.location=/home/ec2-user/ec2-52-43-209-2403.us-west-2.compute.amazonaws.com.truststore.jks
ssl.truststore.password=password
inter.broker.listener.name=SSL
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/home/ec2-user/kafka-logs
num.partitions=8
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.retention.check.interval.ms=300000
advertised.host.name=localhost
zookeeper.connect=35.90.113.2543:2181,52.43.209.2403:2181,54.187.78.1003:2181
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0



KAFKA2:
-------
cp -r /home/ec2-user/kafka_2.13-3.5.1/config/server.properties /home/ec2-user/kafka_2.13-3.5.1/config/server.properties-bkp
vi /home/ec2-user/kafka_2.13-3.5.1/config/server.properties
broker.id=2
listeners=SSL://0.0.0.0:9093
#advertised.listeners=SSL://<SERVER2_PUBLIC_DNS>:9093
advertised.listeners=SSL://ec2-52-43-209-2403.us-west-2.compute.amazonaws.com:9093
ssl.keystore.location=/home/ec2-user/ec2-52-43-209-2403.us-west-2.compute.amazonaws.com.keystore.jks
ssl.keystore.password=password
ssl.key.password=password
ssl.truststore.location=/home/ec2-user/ec2-52-43-209-2403.us-west-2.compute.amazonaws.com.truststore.jks
ssl.truststore.password=password
inter.broker.listener.name=SSL
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/home/ec2-user/kafka-logs
num.partitions=8
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.retention.check.interval.ms=300000
advertised.host.name=localhost
zookeeper.connect=35.90.113.2543:2181,52.43.209.2403:2181,54.187.78.1003:2181
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0



KAFKA3:
-------
cp -r /home/ec2-user/kafka_2.13-3.5.1/config/server.properties /home/ec2-user/kafka_2.13-3.5.1/config/server.properties-bkp
vi /home/ec2-user/kafka_2.13-3.5.1/config/server.properties
broker.id=3
listeners=SSL://0.0.0.0:9093
#advertised.listeners=SSL://<SERVER3_PUBLIC_DNS>:9093
advertised.listeners=SSL://ec2-54-187-78-1003.us-west-2.compute.amazonaws.com:9093
ssl.keystore.location=/home/ec2-user/ec2-54-187-78-1003.us-west-2.compute.amazonaws.com.keystore.jks
ssl.keystore.password=password
ssl.key.password=password
ssl.truststore.location=/home/ec2-user/ec2-54-187-78-1003.us-west-2.compute.amazonaws.com.truststore.jks
ssl.truststore.password=password
inter.broker.listener.name=SSL
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/home/ec2-user/kafka-logs
num.partitions=8
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.retention.check.interval.ms=300000
advertised.host.name=localhost
zookeeper.connect=35.90.113.2543:2181,52.43.209.2403:2181,54.187.78.1003:2181
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0



START KAFKA:-
=============
start kafka in all SERVER1,SERVER2,SERVER3 instances at once

/home/ec2-user/kafka_2.13-3.5.1/bin/kafka-server-start.sh /home/ec2-user/kafka_2.13-3.5.1/config/server.properties

/home/ec2-user/kafka_2.13-3.5.1/bin/kafka-server-start.sh -daemon /home/ec2-user/kafka_2.13-3.5.1/config/server.properties

KAFKA LOGS:-
============
tail -f -n 100 /home/ec2-user/kafka_2.13-3.5.1/logs/server.log

[2023-07-30 18:25:45,935] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2023-07-30 18:25:46,149] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2023-07-30 18:25:46,150] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)


[ec2-user@kafka1 logs]$ echo dump | nc localhost 2181 | grep brokers
        /brokers/ids/1
        /brokers/ids/2
        /brokers/ids/3

/home/ec2-user/kafka_2.13-3.5.1/bin/kafka-server-stop.sh /home/ec2-user/kafka_2.13-3.5.1/config/server.properties



CONFIGURING ZOOKEEPER AND KAFKA AS SERVICE:-
============================================
execute in all 3 SERVER1,SERVER2,SERVER3 servers

ZOOKEEPER:
----------
sudo vi /etc/systemd/system/zookeeper.service
[Unit]
Description=Apache ZooKeeper
Documentation=http://zookeeper.apache.org
Requires=network.target remote-fs.target
After=network.target remote-fs.target
[Service]
Type=simple
User=ec2-user
Group=ec2-user
ExecStart=/home/ec2-user/kafka_2.13-3.5.1/bin/zookeeper-server-start.sh /home/ec2-user/kafka_2.13-3.5.1/config/zookeeper.properties
ExecStop=/home/ec2-user/kafka_2.13-3.5.1/bin/zookeeper-server-stop.sh
Restart=on-failure
RestartSec=5s
[Install]
WantedBy=multi-user.target

sudo systemctl daemon-reload
sudo systemctl enable zookeeper
sudo systemctl start zookeeper
sudo systemctl status zookeeper
sudo systemctl stop zookeeper

KAFKA:
------
sudo vi /etc/systemd/system/kafka.service
[Unit]
Description=Apache Kafka
Documentation=http://kafka.apache.org
Requires=zookeeper.service
After=zookeeper.service
[Service]
Type=simple
User=ec2-user
Group=ec2-user
ExecStart=/home/ec2-user/kafka_2.13-3.5.1/bin/kafka-server-start.sh /home/ec2-user/kafka_2.13-3.5.1/config/server.properties
# Uncomment the following line if you want Kafka to run as a background (daemon) process
# ExecStart=/home/ec2-user/kafka_2.13-3.5.1/bin/kafka-server-start.sh -daemon /home/ec2-user/kafka_2.13-3.5.1/config/server.properties
ExecStop=/home/ec2-user/kafka_2.13-3.5.1/bin/kafka-server-stop.sh
Restart=on-failure
RestartSec=5s
[Install]
WantedBy=multi-user.target

sudo systemctl daemon-reload
sudo systemctl enable kafka
sudo systemctl start kafka
sudo systemctl status kafka
sudo systemctl stop kafka



[ec2-user@kafka1 ~]$ echo dump | nc localhost 2181
SessionTracker dump:
Global Sessions(3):
0x10002d7158b0003       18000ms
0x20002d711b50004       18000ms
0x30002d71fc60005       18000ms
ephemeral nodes dump:
Sessions with Ephemerals (3):
0x30002d71fc60005:
        /brokers/ids/2
0x20002d711b50004:
        /brokers/ids/3
0x10002d7158b0003:
        /controller
        /brokers/ids/1
Connections dump:
Connections Sets (2)/(2):
0 expire at Tue Aug 01 16:32:27 UTC 2023:
2 expire at Tue Aug 01 16:32:37 UTC 2023:
        ip: /127.0.0.1:33308 sessionId: 0x0
        ip: /35.90.113.254:52988 sessionId: 0x10002d7158b0003
#############################################################################################################################################################
#############################################################################################################################################################

SSL Setup for Clients:-
========================

Take another local server(an aws instance or vagrant local machine or local development box)
- we have already created certificates for client in SERVER1 by using script certs.sh,and password for all is present in cert_creds file, now we need to copy those cetificates to all clients which are needed
- for now,
we will take SERVER1 as client1
we will take SERVER2 as client2
we will take SERVER3 as client3

SENDING FOR SERVER1/Local:
--------------------------
cd /home/ec2-user/ssl/secrets
cp -r client.keystore.jks client.truststore.jks /home/ec2-user/

SENDING FOR SERVER2:
--------------------
scp -i /home/ec2-user/ssl/secrets/server.pem client.keystore.jks client.truststore.jks ec2-user@ec2-52-43-209-2403.us-west-2.compute.amazonaws.com:/home/ec2-user/ 

SENDING FOR SERVER3:
--------------------
scp -i /home/ec2-user/ssl/secrets/server.pem client.keystore.jks client.truststore.jks ec2-user@ec2-54-187-78-1003.us-west-2.compute.amazonaws.com:/home/ec2-user/ 


## create client.properties and configure SSL parameters in all clients i.e SERVER1,SERVER2,SERVER3
cd /home/ec2-user
vi client.properties

bootstrap.servers=ec2-35-90-113-2543.us-west-2.compute.amazonaws.com:9093,ec2-52-43-209-2403.us-west-2.compute.amazonaws.com:9093,ec2-54-187-78-1003.us-west-2.compute.amazonaws.com:9093
security.protocol=SSL
ssl.truststore.location=/home/ec2-user/client.truststore.jks
ssl.truststore.password=password
ssl.keystore.location=/home/ec2-user/client.keystore.jks
ssl.keystore.password=password




## TESTING PRODUCER AND CONSUMER:-
===================================
test using the console-consumer and console-producer 

list topics:
------------
/home/ec2-user/kafka_2.13-3.5.1/bin/kafka-topics.sh --bootstrap-server ec2-35-90-113-2543.us-west-2.compute.amazonaws.com:9093,ec2-52-43-209-2403.us-west-2.compute.amazonaws.com:9093,ec2-54-187-78-1003.us-west-2.compute.amazonaws.com:9093 --list --command-config /home/ec2-user/client.properties


[ec2-user@kafka1 bin]$ /home/ec2-user/kafka_2.13-3.5.1/bin/kafka-topics.sh --bootstrap-server ec2-35-90-113-2543.us-west-2.compute.amazonaws.com:9093,ec2-52-43-209-2403.us-west-2.compute.amazonaws.com:9093,ec2-54-187-78-1003.us-west-2.compute.amazonaws.com:9093 --list --command-config /home/ec2-user/client.properties

myTopic


### Producer
ON SERVER1/CLIENT1:
-------------------
/home/ec2-user/kafka_2.13-3.5.1/bin/kafka-console-producer.sh --bootstrap-server ec2-35-90-113-2543.us-west-2.compute.amazonaws.com:9093,ec2-52-43-209-2403.us-west-2.compute.amazonaws.com:9093,ec2-54-187-78-1003.us-west-2.compute.amazonaws.com:9093 --topic myTopic --producer.config /home/ec2-user/client.properties

[ec2-user@kafka1 bin]$ /home/ec2-user/kafka_2.13-3.5.1/bin/kafka-console-producer.sh --bootstrap-server ec2-35-90-113-2543.us-west-2.compute.amazonaws.com:9093,ec2-52-43-209-2403.us-west-2.compute.amazonaws.com:9093,ec2-54-187-78-1003.us-west-2.compute.amazonaws.com:9093 --topic myTopic --producer.config /home/ec2-user/client.properties
>Hi, Vijay producer is here, are you ready to consume ??
>

And you can see that we were able to successfully produce a message to our SSL enabled endpoint. on port 9093


But now let's also test what happens if we don't provide the required cell properties and we are trying to connect to the SSL endpoint of our Kafka broker. So as you can see that the producer still starts up and it tries to add a message, but it doesn't come back to us.

~/kafka/bin/kafka-console-producer.sh --broker-list <<your-public-DNS>>:9093 --topic kafka-security-topic


### Consumer
ON SERVER2/CLIENT2:
-------------------

/home/ec2-user/kafka_2.13-3.5.1/bin/kafka-console-consumer.sh --bootstrap-server ec2-35-90-113-2543.us-west-2.compute.amazonaws.com:9093,ec2-52-43-209-2403.us-west-2.compute.amazonaws.com:9093,ec2-54-187-78-1003.us-west-2.compute.amazonaws.com:9093 --topic myTopic --consumer.config /home/ec2-user/client.properties --from-beginning

[ec2-user@kafka2 ~]$ /home/ec2-user/kafka_2.13-3.5.1/bin/kafka-console-consumer.sh --bootstrap-server ec2-35-90-113-2543.us-west-2.compute.amazonaws.com:9093,ec2-52-43-209-2403.us-west-2.compute.amazonaws.com:9093,ec2-54-187-78-1003.us-west-2.compute.amazonaws.com:9093 --topic myTopic --consumer.config /home/ec2-user/client.properties --from-beginning
Hi Vijay producer is here, are you ready to consume ??


